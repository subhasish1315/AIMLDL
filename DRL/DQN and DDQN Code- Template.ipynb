{"cells":[{"cell_type":"markdown","source":["### `---------------Mandatory Information to fill------------`"],"metadata":{"id":"j7jO_ata_tGB"},"id":"j7jO_ata_tGB"},{"cell_type":"markdown","source":["### Group ID:\n","### Group Members Name with Student ID:\n","1. Student 1\n","2. Student 2\n","3. Student 3\n","4. Student 4"],"metadata":{"id":"ilJIt-lgIp04"},"id":"ilJIt-lgIp04"},{"cell_type":"markdown","source":["`-------------------Write your remarks (if any) that you want should get consider at the time of evaluation---------------`"],"metadata":{"id":"YXHhoNgkAhUg"},"id":"YXHhoNgkAhUg"},{"cell_type":"markdown","source":["Remarks: ##Add here"],"metadata":{"id":"-5tK16CbA5X_"},"id":"-5tK16CbA5X_"},{"cell_type":"markdown","id":"cc769279","metadata":{"id":"cc769279"},"source":["## Autonomous Drone Battery Management for Urban Surveillance using DQN and DDQN - 7 Marks"]},{"cell_type":"markdown","id":"f9229188","metadata":{"id":"f9229188"},"source":["### Import Statements"]},{"cell_type":"code","execution_count":null,"id":"893bf5df","metadata":{"id":"893bf5df"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from collections import deque\n","import random\n","import matplotlib.pyplot as plt\n","import time"]},{"cell_type":"code","execution_count":null,"id":"63b0a4b1","metadata":{"id":"63b0a4b1"},"outputs":[],"source":["# --- 1. Hyperparameters and Constants ---\n","\n","# Environment Parameters\n","GRID_SIZE = (10, 10) # X, Y\n","BATTERY_CAPACITY = 100.0 # Percentage\n","INITIAL_BATTERY = 100.0\n","\n","BASE_MOVE_COST = 0.5 # % battery per step\n","BASE_HOVER_COST = 0.2 # % battery per step\n","RECHARGE_RATE = 5.0 # % battery per step when recharging\n","\n","BATTERY_CRASH_PENALTY = -100.0\n","TIME_PENALTY = -0.1 # Small penalty for each time step\n","RECHARGE_BONUS = 1.0 # Small bonus for successfully recharging\n","\n","# POI Parameters\n","POI_SPAWN_CHANCE = 0.05 # Probability to spawn a new POI each step\n","MAX_ACTIVE_POIS = 3 # Max number of POIs active at once\n","POI_LIFESPAN_RANGE = (10, 30) # Min, Max timesteps a POI is active\n","POI_VALUE_RANGE = (10, 50) # Min, Max surveillance score for a POI\n","\n","# Atmospheric Disturbance Parameters\n","DISTURBANCE_FACTOR = 0.5 # Multiplier for disturbance effect on battery cost\n","DISTURBANCE_CHANGE_PROB = 0.1 # Probability disturbance changes randomly each step\n","DISTURBANCE_MAGNITUDE_CHANGE = 0.1 # Max change when disturbance updates\n","\n","# Agent Parameters\n","STATE_SIZE = 7 # [drone_x, drone_y, battery_level, disturbance, nearest_poi_dist, nearest_poi_value, nearest_poi_lifespan]\n","ACTION_SIZE = 6 # North, South, East, West, Hover, Recharge\n","\n","LEARNING_RATE =\n","DISCOUNT_FACTOR =  # Gamma\n","\n","REPLAY_BUFFER_SIZE =\n","MIN_REPLAY_SIZE =  # Start learning after this many experiences\n","BATCH_SIZE =\n","\n","EXPLORATION_MAX =\n","EXPLORATION_MIN =\n","EXPLORATION_DECAY = # Decay epsilon over time\n","\n","TARGET_UPDATE_FREQUENCY =  # How often to update the target network\n","\n","# Training Parameters\n","EPISODES = 500 # Number of training episodes (24-hour cycles)\n","MAX_TIMESTEPS_PER_EPISODE = 200 # Represents a 24-hour cycle (or portion)\n","\n"]},{"cell_type":"code","execution_count":null,"id":"dc3d02d5","metadata":{"id":"dc3d02d5"},"outputs":[],"source":["# --- 2. Replay Buffer Class ---"]},{"cell_type":"markdown","id":"84904415","metadata":{"id":"84904415"},"source":["### --- 3. Custom Environment: DroneSurveillanceEnv --- - 2 Marks"]},{"cell_type":"code","execution_count":null,"id":"d06cc56b","metadata":{"id":"d06cc56b"},"outputs":[],"source":["# Develop the DroneSurveillanceEnv including the __init__, step,\n","# and reset methods. Accurately model battery dynamics (depletion, recharge, capacity limits).\n","# mplement dynamic POI spawning, value collection, and lifespan decay.\n","# Model random atmospheric disturbances and their effect on energy consumption.\n","\n","class DroneSurveillanceEnv:\n","    def __init__(self, grid_size, battery_capacity, initial_battery):\n","\n","         # Drone State\n","\n","         # Environmental Dynamics\n","\n","         # Charging Stations (fixed locations)\n","\n","         # Action mapping: 0:N, 1:S, 2:E, 3:W, 4:Hover, 5:Recharge\n","\n","    def reset(self):\n","\n","\n","    def _get_obs(self):\n","        \"\"\"\n","        Converts the internal environment state into the observation vector for the NN.\n","        \"\"\"\n","        # --- POI Information ---\n","\n","    def _spawn_poi(self):\n","\n","        # Check if cell is occupied by drone, charging station, or existing POI\n","\n","    def _update_pois(self, drone_at_poi_pos):\n","\n","\n","    def _update_atmospheric_disturbance(self):\n","\n","    def step(self, action):\n","\n","         # --- Update Atmospheric Disturbance ---\n","\n","          # --- Battery Consumption / Recharge ---\n","\n","          # Move actions - Apply movement, Ensure drone stays within grid boundaries\n","\n","          # --- Check for Crash ---\n","\n","          # --- Update POIs and Collect Rewards ---\n","\n","          # --- Spawn new POIs randomly ---\n","\n","          # --- Add time penalty ---\n","\n","    def render(self):\n","\n","         # Mark Charging Stations\n","         # Mark Active POIs\n","         # Mark Drone\n","         # Print grid"]},{"cell_type":"markdown","id":"20870303","metadata":{"id":"20870303"},"source":["### --- 4. DQNAgent Class --- 1 Mark"]},{"cell_type":"code","execution_count":null,"id":"0ad0e34f","metadata":{"id":"0ad0e34f"},"outputs":[],"source":["\n","class DQNAgent:\n","    def __init__(self, state_size, action_size, use_ddqn=False):\n","\n","\n","    def _build_model(self):\n","        \"\"\"\n","        Builds the neural network for the Q-function.\n","        Input: State vector (STATE_SIZE)\n","        Output: Q-values for each action (ACTION_SIZE)\n","        \"\"\"\n","    def update_target_network(self):\n","\n","\n","    def choose_action(self, state):\n","\n","    def learn(self):"]},{"cell_type":"markdown","id":"7829f4de","metadata":{"id":"7829f4de"},"source":["### --- 5. Main Training Loop --- 1 Mark"]},{"cell_type":"code","execution_count":null,"id":"201753a6","metadata":{"id":"201753a6"},"outputs":[],"source":["\n","def train_agent(env, agent, num_episodes, max_timesteps_per_episode, render=False):\n","\n","    # Store initial weights for comparison (optional)\n","    # initial_weights = agent.q_network.get_weights()\n","\n","    # Perform learning step after each episode\n","\n","\n","    # Update target network periodically"]},{"cell_type":"markdown","id":"a5d4aff0","metadata":{"id":"a5d4aff0"},"source":["### --- Main Execution Block ---"]},{"cell_type":"code","execution_count":null,"id":"33b42e91","metadata":{"id":"33b42e91"},"outputs":[],"source":["\n","\n","if __name__ == \"__main__\":\n","    # Ensure TensorFlow uses GPU if available\n","\n","    env = DroneSurveillanceEnv(GRID_SIZE, BATTERY_CAPACITY, INITIAL_BATTERY)\n","\n","\n","    # --- Train DQN Agent ---\n","\n","\n","    # --- Train Double DQN Agent --- 1 Mark\n","\n","\n","    # --- Plotting Results ---\n","\n","    # --- Policy Analysis --- 1 Mark\n","\n","    # --- Evaluation of running a single episode with the learned policy --- 1 Mark\n"]},{"cell_type":"markdown","id":"001705ed","metadata":{"id":"001705ed"},"source":["### Hyperparameter Tuning & Discussion: (1 Mark)"]},{"cell_type":"markdown","id":"eeeee5c5","metadata":{"id":"eeeee5c5"},"source":[]}],"metadata":{"language_info":{"name":"python"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}